{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cd24337-b5ad-4ba8-84d8-25ebdf8ddba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df=pd.read_excel(\"Data_For Model 20230107.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e64bb1-f247-4f80-b03b-bd33d378d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "tqdm.pandas()\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" ###指定此处为-1即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a62e0e-2201-488b-a062-d74c5724e42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "IS    8131\n",
       "ES    3093\n",
       "iS       1\n",
       "b        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1cd72e1-b7fd-416e-837a-e155ce02409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpd={\"IS\":0,\"ES\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d4a7900-d291-4f9a-af31-6b40a482eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"]=df[\"Label\"].map(tmpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90850fd3-8ca2-4a55-b312-f7f4d5ca8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1541e68-236a-4620-aeb7-2f4258fd5cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    8131\n",
       "1.0    3093\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe083b3e-8354-4d0b-8ea9-eb265d6db722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]=df[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b3cc8d-284b-4566-9acd-f6dcd881cf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>别担心，这种情况是可以解决的</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>别担心，这种情况是可以解决的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>遇到这种事情是很麻烦的，不是三言两语可以解决的，要具体问题具体对待，希望你们和睦相处，开心快乐！</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>遇到这种事情是很麻烦的，不是三言两语可以解决的，要具体问题具体对待，希望你们和睦相处，开心快乐！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>我的已经到了，希望大家的也马上到达。</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>我的已经到了，希望大家的也马上到达。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>呵呵，人力搜索中——查找！</td>\n",
       "      <td>IS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>呵呵，人力搜索中——查找！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>寻找共同爱好，比如游戏等</td>\n",
       "      <td>IS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>寻找共同爱好，比如游戏等</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11221</th>\n",
       "      <td>NaN</td>\n",
       "      <td>这个也很好玩耶！</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>这个也很好玩耶！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11222</th>\n",
       "      <td>NaN</td>\n",
       "      <td>太强了</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>太强了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>我非常赞同这位同学的看法</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>我非常赞同这位同学的看法</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>我觉得您的想法和思维导图做的不错！</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>我觉得您的想法和思维导图做的不错！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11225</th>\n",
       "      <td>NaN</td>\n",
       "      <td>嗯嗯，我同意你们两个的说法</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>嗯嗯，我同意你们两个的说法</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11224 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              Text Label   \n",
       "0             NaN                                    别担心，这种情况是可以解决的    ES  \\\n",
       "1             NaN  遇到这种事情是很麻烦的，不是三言两语可以解决的，要具体问题具体对待，希望你们和睦相处，开心快乐！    ES   \n",
       "2             NaN                                我的已经到了，希望大家的也马上到达。    ES   \n",
       "3             NaN                                     呵呵，人力搜索中——查找！    IS   \n",
       "4             NaN                                      寻找共同爱好，比如游戏等    IS   \n",
       "...           ...                                               ...   ...   \n",
       "11221         NaN                                          这个也很好玩耶！    ES   \n",
       "11222         NaN                                               太强了    ES   \n",
       "11223         NaN                                      我非常赞同这位同学的看法    ES   \n",
       "11224         NaN                                 我觉得您的想法和思维导图做的不错！    ES   \n",
       "11225         NaN                                     嗯嗯，我同意你们两个的说法    ES   \n",
       "\n",
       "       label                                              text  \n",
       "0        1.0                                    别担心，这种情况是可以解决的  \n",
       "1        1.0  遇到这种事情是很麻烦的，不是三言两语可以解决的，要具体问题具体对待，希望你们和睦相处，开心快乐！  \n",
       "2        1.0                                我的已经到了，希望大家的也马上到达。  \n",
       "3        0.0                                     呵呵，人力搜索中——查找！  \n",
       "4        0.0                                      寻找共同爱好，比如游戏等  \n",
       "...      ...                                               ...  \n",
       "11221    1.0                                          这个也很好玩耶！  \n",
       "11222    1.0                                               太强了  \n",
       "11223    1.0                                      我非常赞同这位同学的看法  \n",
       "11224    1.0                                 我觉得您的想法和思维导图做的不错！  \n",
       "11225    1.0                                     嗯嗯，我同意你们两个的说法  \n",
       "\n",
       "[11224 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e92532-892c-498b-833b-39e4b36daa70",
   "metadata": {},
   "source": [
    "#### 去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5590d17e-c9df-4213-93ab-a4968d7099c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\jhg\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.882 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import jieba_fast as jieba\n",
    "ting=[i.strip() for i in open(\"stop_words_ch-停用词表.txt\",encoding='gbk').readlines()]\n",
    "def fenci(text):\n",
    "    return [i for i in jieba.cut(str(text)) if i not in ting] \n",
    "\n",
    "df[\"text\"]=df[\"text\"].apply(lambda x:fenci(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e711cb25-1af6-42fc-b7f0-74ff360138a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]=df[\"text\"].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4740381-84b0-4c60-9bcd-e075c9db8d6f",
   "metadata": {},
   "source": [
    "### 深度学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c638d-2a1e-4af7-8a8d-d0e4e65aafaa",
   "metadata": {},
   "source": [
    "#### w2v加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f05de-71ea-4bed-aa73-671d424922a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "if not os.path.exists(\"w2v\"):\n",
    "    w2v_model = gensim.models.Word2Vec(list(df[\"text\"]), vector_size=128, epochs=10, min_count=0)\n",
    "    word_vectors = w2v_model.wv\n",
    "    w2v_model.save(\"w2v\")\n",
    "else:\n",
    "    print (\"直接加载训练好的w2v模型\")\n",
    "    w2v_model=gensim.models.Word2Vec.load(\"w2v\")\n",
    "    word_vectors = w2v_model.wv\n",
    "    print (\"w2v模型加载完毕\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada1b07-6dad-45aa-ae8a-09225b4d570d",
   "metadata": {},
   "source": [
    "#### 转向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0515a873-9d24-4ca3-9996-0959657f2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "x_train=list(df[\"text\"])\n",
    "if not os.path.exists(\"tokenizer.joblib\"):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x_train)  #统计每个词对应的数字，以便于将文本转化成向量\n",
    "    joblib.dump(tokenizer,\"tokenizer.joblib\")\n",
    "else:\n",
    "    print(\"加载token\")\n",
    "    tokenizer=joblib.load(\"tokenizer.joblib\")\n",
    "train_sequence = tokenizer.texts_to_sequences(x_train)#将所有的文本转化成向量\n",
    "MAX_SEQUENCE_LENGTH=64 #最大长度\n",
    "EMBEDDING_DIM = 128 #向量维度\n",
    "\n",
    "y_train =df[\"label\"]\n",
    "y_train = to_categorical(y_train)  #将标签 one-hot\n",
    "y_train = y_train.astype(np.int32)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "train_pad = pad_sequences(train_sequence, maxlen=MAX_SEQUENCE_LENGTH) #将每条文本按照最大长度补0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97597dee-e8be-4c91-b2e5-9444cdf5e247",
   "metadata": {},
   "source": [
    "#### 嵌入矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d3c39-64f5-40ed-a955-69426d7487ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM), dtype=np.float32)\n",
    "not_in_model = 0\n",
    "in_model = 0\n",
    "embedding_max_value = 0\n",
    "embedding_min_value = 1\n",
    "not_words = []\n",
    "\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    if word in w2v_model.wv.key_to_index:\n",
    "        in_model += 1\n",
    "        embedding_matrix[i] = np.array(w2v_model.wv[word])\n",
    "        embedding_max_value = max(np.max(embedding_matrix[i]), embedding_max_value)\n",
    "        embedding_min_value = min(np.min(embedding_matrix[i]), embedding_min_value)\n",
    "    else:\n",
    "        not_in_model += 1\n",
    "        not_words.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa092580-5995-493c-9ade-4d397d6243b6",
   "metadata": {},
   "source": [
    "#### 构建二分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ac196-2967-4330-b431-df37638bf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnnmodel(class_num=2):\n",
    "    embed = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH,\n",
    "\t\t\t\t  trainable=True)  #定义一个词嵌入层,将句子转化成对应的向量\n",
    "    inputs_sentence = Input(shape=(MAX_SEQUENCE_LENGTH,))#设置输入向量维度\n",
    "    sentence =embed(inputs_sentence)#定义词嵌入层\n",
    "    kernel_sizes=[13,14,15]\n",
    "    convs = []\n",
    "    max_poolings = []\n",
    "    for kernel_size in kernel_sizes:\n",
    "        convs.append(Conv1D(64, kernel_size, activation='relu'))\n",
    "        max_poolings.append(GlobalMaxPooling1D())\n",
    "    convs1 = []\n",
    "    for i in range(len(kernel_sizes)):\n",
    "        c = convs[i](sentence)\n",
    "        c = max_poolings[i](c)\n",
    "        convs1.append(c)\n",
    "    x = Concatenate()(convs1)\n",
    "#     x=Dense(64, activation='relu')(x)\n",
    "    dp=Dropout(0.1)(x)\n",
    "    output = Dense(class_num, activation='softmax')(dp)#softmax层\n",
    "    model = Model(inputs=[inputs_sentence], outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])#定义损失函数，优化器，评分标准\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfd4e5-fd19-40b9-9dfd-aa13cb73d230",
   "metadata": {},
   "source": [
    "### 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4194c6d7-7beb-40e8-b625-62dc97d7b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0f3f8-ea6d-48a8-8c1c-f0a546a3eed3",
   "metadata": {},
   "source": [
    "### 每一折的交叉验证报告 手动平均即为交叉验证的平均结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73b59f8a-d18f-4e60-b274-ba7e6a58cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9468    0.7461    0.8345      1646\n",
      "          ES     0.5591    0.8848    0.6852       599\n",
      "\n",
      "    accuracy                         0.7831      2245\n",
      "   macro avg     0.7529    0.8154    0.7599      2245\n",
      "weighted avg     0.8433    0.7831    0.7947      2245\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9335    0.7392    0.8250      1614\n",
      "          ES     0.5646    0.8653    0.6834       631\n",
      "\n",
      "    accuracy                         0.7746      2245\n",
      "   macro avg     0.7491    0.8022    0.7542      2245\n",
      "weighted avg     0.8298    0.7746    0.7852      2245\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9425    0.7407    0.8295      1639\n",
      "          ES     0.5559    0.8779    0.6807       606\n",
      "\n",
      "    accuracy                         0.7777      2245\n",
      "   macro avg     0.7492    0.8093    0.7551      2245\n",
      "weighted avg     0.8382    0.7777    0.7894      2245\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9456    0.7253    0.8210      1631\n",
      "          ES     0.5493    0.8893    0.6791       614\n",
      "\n",
      "    accuracy                         0.7702      2245\n",
      "   macro avg     0.7475    0.8073    0.7500      2245\n",
      "weighted avg     0.8372    0.7702    0.7822      2245\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9367    0.7214    0.8151      1601\n",
      "          ES     0.5589    0.8787    0.6832       643\n",
      "\n",
      "    accuracy                         0.7665      2244\n",
      "   macro avg     0.7478    0.8001    0.7491      2244\n",
      "weighted avg     0.8285    0.7665    0.7773      2244\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9468    0.7461    0.8345      1646\n",
      "          ES     0.5591    0.8848    0.6852       599\n",
      "\n",
      "    accuracy                         0.7831      2245\n",
      "   macro avg     0.7529    0.8154    0.7599      2245\n",
      "weighted avg     0.8433    0.7831    0.7947      2245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9335    0.7392    0.8250      1614\n",
      "          ES     0.5646    0.8653    0.6834       631\n",
      "\n",
      "    accuracy                         0.7746      2245\n",
      "   macro avg     0.7491    0.8022    0.7542      2245\n",
      "weighted avg     0.8298    0.7746    0.7852      2245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9425    0.7407    0.8295      1639\n",
      "          ES     0.5559    0.8779    0.6807       606\n",
      "\n",
      "    accuracy                         0.7777      2245\n",
      "   macro avg     0.7492    0.8093    0.7551      2245\n",
      "weighted avg     0.8382    0.7777    0.7894      2245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9456    0.7253    0.8210      1631\n",
      "          ES     0.5493    0.8893    0.6791       614\n",
      "\n",
      "    accuracy                         0.7702      2245\n",
      "   macro avg     0.7475    0.8073    0.7500      2245\n",
      "weighted avg     0.8372    0.7702    0.7822      2245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9367    0.7214    0.8151      1601\n",
      "          ES     0.5589    0.8787    0.6832       643\n",
      "\n",
      "    accuracy                         0.7665      2244\n",
      "   macro avg     0.7478    0.8001    0.7491      2244\n",
      "weighted avg     0.8285    0.7665    0.7773      2244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=train_pad\n",
    "y=y_train\n",
    "true_labels_all = []\n",
    "predicted_labels_all = []\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    \n",
    "    model=get_cnnmodel()\n",
    "    callbacks = [EarlyStopping(monitor='val_acc', min_delta=0.001, patience=10),\n",
    "\t\t\t ModelCheckpoint(\"textcnn.hdf5\", monitor='val_acc',\n",
    "\t\t\t\t\t\t\t mode='max', verbose=0, save_best_only=True,save_weights_only=True)]   \n",
    "    #设置模型提前停止,停止的条件是验证集val_acc两轮已经不增加,保存验证集val_acc最大的那个模型,名称为new_cnn.hdf5\n",
    "    history=model.fit(X_train,y_train, batch_size=64, epochs=20, callbacks=callbacks,validation_data=(X_test,y_test))\n",
    "\n",
    "    model.load_weights(\"textcnn.hdf5\")\n",
    "    testpre=np.argmax(model.predict([X_test]),axis=1)\n",
    "    import matplotlib.pyplot as plt\n",
    "    val_loss = history.history['val_loss']\n",
    "    loss = history.history['loss']\n",
    "    epochs = range(1, len(loss ) + 1)\n",
    "    plt.title('cnn_Loss')\n",
    "    plt.plot(epochs, loss, 'red', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'blue', label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.cla()\n",
    "\n",
    "    val_loss = history.history['val_acc']\n",
    "    loss = history.history['acc']\n",
    "    epochs = range(1, len(loss ) + 1)\n",
    "    plt.title('cnn_acc')\n",
    "    plt.plot(epochs, loss, 'red', label='Training acc')\n",
    "    plt.plot(epochs, val_loss, 'blue', label='Validation acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    from sklearn.metrics import classification_report\n",
    "    tmpd={\"IS\":0,\"ES\":1}\n",
    "    print (classification_report(np.argmax(y_test,axis=1),testpre,digits=4,target_names=list(tmpd.keys())))\n",
    "    true_labels_all.extend(np.argmax(y_test,axis=1))\n",
    "    predicted_labels_all.extend(testpre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0c7a3-bed1-4a77-8caf-e54210a794d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将结果转换为numpy数组\n",
    "true_labels_all = np.array(true_labels_all)\n",
    "predicted_labels_all = np.array(predicted_labels_all)\n",
    "\n",
    "# 创建一个DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'True_Label': true_labels_all,\n",
    "    'Predicted_Label': predicted_labels_all\n",
    "})\n",
    "\n",
    "# 将DataFrame保存为CSV文件\n",
    "results_df.to_csv('cnn_cross_validation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
