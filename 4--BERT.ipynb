{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cd24337-b5ad-4ba8-84d8-25ebdf8ddba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df=pd.read_excel(\"Data_For Model 20230107.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e64bb1-f247-4f80-b03b-bd33d378d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from bert4keras.backend import keras, search_layer, K\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.optimizers import Adam\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from tensorflow.keras.layers import Lambda, Dense,Bidirectional,LSTM\n",
    "from tensorflow.keras.losses import kullback_leibler_divergence as kld\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "labels = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a62e0e-2201-488b-a062-d74c5724e42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "IS    8131\n",
       "ES    3093\n",
       "iS       1\n",
       "b        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1cd72e1-b7fd-416e-837a-e155ce02409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpd={\"IS\":0,\"ES\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d4a7900-d291-4f9a-af31-6b40a482eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"]=df[\"Label\"].map(tmpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90850fd3-8ca2-4a55-b312-f7f4d5ca8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1541e68-236a-4620-aeb7-2f4258fd5cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    8131\n",
       "1.0    3093\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe083b3e-8354-4d0b-8ea9-eb265d6db722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]=df[\"Text\"]\n",
    "df=df.dropna(subset=[\"text\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b3cc8d-284b-4566-9acd-f6dcd881cf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>别担心，这种情况是可以解决的</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>别担心，这种情况是可以解决的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>遇到这种事情是很麻烦的，不是三言两语可以解决的，要具体问题具体对待，希望你们和睦相处，开心快乐！</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>遇到这种事情是很麻烦的，不是三言两语可以解决的，要具体问题具体对待，希望你们和睦相处，开心快乐！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>我的已经到了，希望大家的也马上到达。</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>我的已经到了，希望大家的也马上到达。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>呵呵，人力搜索中——查找！</td>\n",
       "      <td>IS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>呵呵，人力搜索中——查找！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>寻找共同爱好，比如游戏等</td>\n",
       "      <td>IS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>寻找共同爱好，比如游戏等</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11221</th>\n",
       "      <td>NaN</td>\n",
       "      <td>这个也很好玩耶！</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>这个也很好玩耶！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11222</th>\n",
       "      <td>NaN</td>\n",
       "      <td>太强了</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>太强了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>我非常赞同这位同学的看法</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>我非常赞同这位同学的看法</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>我觉得您的想法和思维导图做的不错！</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>我觉得您的想法和思维导图做的不错！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11225</th>\n",
       "      <td>NaN</td>\n",
       "      <td>嗯嗯，我同意你们两个的说法</td>\n",
       "      <td>ES</td>\n",
       "      <td>1.0</td>\n",
       "      <td>嗯嗯，我同意你们两个的说法</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11224 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              Text Label   \n",
       "0             NaN                                    别担心，这种情况是可以解决的    ES  \\\n",
       "1             NaN  遇到这种事情是很麻烦的，不是三言两语可以解决的，要具体问题具体对待，希望你们和睦相处，开心快乐！    ES   \n",
       "2             NaN                                我的已经到了，希望大家的也马上到达。    ES   \n",
       "3             NaN                                     呵呵，人力搜索中——查找！    IS   \n",
       "4             NaN                                      寻找共同爱好，比如游戏等    IS   \n",
       "...           ...                                               ...   ...   \n",
       "11221         NaN                                          这个也很好玩耶！    ES   \n",
       "11222         NaN                                               太强了    ES   \n",
       "11223         NaN                                      我非常赞同这位同学的看法    ES   \n",
       "11224         NaN                                 我觉得您的想法和思维导图做的不错！    ES   \n",
       "11225         NaN                                     嗯嗯，我同意你们两个的说法    ES   \n",
       "\n",
       "       label                                              text  \n",
       "0        1.0                                    别担心，这种情况是可以解决的  \n",
       "1        1.0  遇到这种事情是很麻烦的，不是三言两语可以解决的，要具体问题具体对待，希望你们和睦相处，开心快乐！  \n",
       "2        1.0                                我的已经到了，希望大家的也马上到达。  \n",
       "3        0.0                                     呵呵，人力搜索中——查找！  \n",
       "4        0.0                                      寻找共同爱好，比如游戏等  \n",
       "...      ...                                               ...  \n",
       "11221    1.0                                          这个也很好玩耶！  \n",
       "11222    1.0                                               太强了  \n",
       "11223    1.0                                      我非常赞同这位同学的看法  \n",
       "11224    1.0                                 我觉得您的想法和思维导图做的不错！  \n",
       "11225    1.0                                     嗯嗯，我同意你们两个的说法  \n",
       "\n",
       "[11224 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e92532-892c-498b-833b-39e4b36daa70",
   "metadata": {},
   "source": [
    "#### 去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5590d17e-c9df-4213-93ab-a4968d7099c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\jhg\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.882 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import jieba_fast as jieba\n",
    "ting=[i.strip() for i in open(\"stop_words_ch-停用词表.txt\",encoding='gbk').readlines()]\n",
    "def fenci(text):\n",
    "    return [i for i in jieba.cut(str(text)) if i not in ting] \n",
    "\n",
    "df[\"text\"]=df[\"text\"].apply(lambda x:fenci(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e711cb25-1af6-42fc-b7f0-74ff360138a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]=df[\"text\"].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4740381-84b0-4c60-9bcd-e075c9db8d6f",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8248194b-fde7-4912-8b66-57941d890872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "num_classes = len(labels)\n",
    "maxlen = 64\n",
    "\n",
    "# BERT base\n",
    "config_path = 'chinese_roberta_www_ext/bert_config.json'\n",
    "checkpoint_path = 'chinese_roberta_www_ext/bert_model.ckpt'\n",
    "dict_path = 'chinese_roberta_www_ext/vocab.txt'\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8be454-ea19-4e35-850b-cf8a38723c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df):\n",
    "    \"\"\"加载数据\n",
    "    单条格式：(文本, 标签id)\n",
    "    \"\"\"\n",
    "\n",
    "    D = []\n",
    "    for i,row in tqdm(df.iterrows()):\n",
    "        D.append((row[\"text\"], labels.index(row[\"label\"])))\n",
    "    return D\n",
    "\n",
    "df=df.dropna(subset=[\"text\"])\n",
    "# 加载数据集\n",
    "df=load_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6a6e37-d872-4242-9393-bc1d86280085",
   "metadata": {},
   "source": [
    "### 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdea1ff-ff58-45a8-82a6-5843d1983d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立分词器\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
    "\n",
    "class data_generator(DataGenerator):\n",
    "    \"\"\"数据生成器\n",
    "    \"\"\"\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "        for is_end, (text, label) in self.sample(random):\n",
    "#             print(text,text1,label)\n",
    "            token_ids, segment_ids = tokenizer.encode(text, maxlen=128)\n",
    "            for i in range(1):\n",
    "                batch_token_ids.append(token_ids)\n",
    "                batch_segment_ids.append(segment_ids)\n",
    "                batch_labels.append([int(label)])\n",
    "            if len(batch_token_ids) == self.batch_size  or is_end:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids,length=128)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids,length=128)\n",
    "                batch_labels = sequence_padding(batch_labels)\n",
    "                yield [batch_token_ids, batch_segment_ids], batch_labels\n",
    "                batch_token_ids, batch_segment_ids, batch_labels = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78623812-2456-4da6-bc55-1881f7eb5f13",
   "metadata": {},
   "source": [
    "### 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f54d8-caa7-49d1-a918-45100a17e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    return_keras_model=False,\n",
    ")\n",
    "output1 = Lambda(lambda x: x[:, 0])(bert.model.output)\n",
    "# tmp=bert.model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3c99be-72b6-44d2-a064-443ed5993fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstmout = Bidirectional(LSTM(128, return_sequences=False))(tmp)\n",
    "output = Dense(\n",
    "    units=len(labels),\n",
    "    activation='softmax',\n",
    "    kernel_initializer=bert.initializer\n",
    ")(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eba260-5332-46c0-b7f0-10f7857c08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Model(bert.model.input, output)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=Adam(2e-5),\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "def evaluate(data):\n",
    "    total, right = 0., 0.\n",
    "    for x_true, y_true in data:\n",
    "        y_pred = model.predict(x_true).argmax(axis=1)\n",
    "        y_true = y_true[:, 0]\n",
    "        total += len(y_true)\n",
    "        right += (y_true == y_pred).sum()\n",
    "    return right / total\n",
    "\n",
    "\n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    \"\"\"评估与保存\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.best_val_acc = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = evaluate(test_generator)\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            model.save_weights('bert1.weights'.format(1))\n",
    "        print(\n",
    "            u'val_acc: %.5f, best_val_acc: %.5f\\n' %\n",
    "            (val_acc, self.best_val_acc)\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfd4e5-fd19-40b9-9dfd-aa13cb73d230",
   "metadata": {},
   "source": [
    "### 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4194c6d7-7beb-40e8-b625-62dc97d7b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0f3f8-ea6d-48a8-8c1c-f0a546a3eed3",
   "metadata": {},
   "source": [
    "### 每一折的交叉验证报告 手动平均即为交叉验证的平均结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73b59f8a-d18f-4e60-b274-ba7e6a58cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9468    0.7461    0.8345      1646\n",
      "          ES     0.5591    0.8848    0.6852       599\n",
      "\n",
      "    accuracy                         0.7831      2245\n",
      "   macro avg     0.7529    0.8154    0.7599      2245\n",
      "weighted avg     0.8433    0.7831    0.7947      2245\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9335    0.7392    0.8250      1614\n",
      "          ES     0.5646    0.8653    0.6834       631\n",
      "\n",
      "    accuracy                         0.7746      2245\n",
      "   macro avg     0.7491    0.8022    0.7542      2245\n",
      "weighted avg     0.8298    0.7746    0.7852      2245\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9425    0.7407    0.8295      1639\n",
      "          ES     0.5559    0.8779    0.6807       606\n",
      "\n",
      "    accuracy                         0.7777      2245\n",
      "   macro avg     0.7492    0.8093    0.7551      2245\n",
      "weighted avg     0.8382    0.7777    0.7894      2245\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9456    0.7253    0.8210      1631\n",
      "          ES     0.5493    0.8893    0.6791       614\n",
      "\n",
      "    accuracy                         0.7702      2245\n",
      "   macro avg     0.7475    0.8073    0.7500      2245\n",
      "weighted avg     0.8372    0.7702    0.7822      2245\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\root\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9367    0.7214    0.8151      1601\n",
      "          ES     0.5589    0.8787    0.6832       643\n",
      "\n",
      "    accuracy                         0.7665      2244\n",
      "   macro avg     0.7478    0.8001    0.7491      2244\n",
      "weighted avg     0.8285    0.7665    0.7773      2244\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9468    0.7461    0.8345      1646\n",
      "          ES     0.5591    0.8848    0.6852       599\n",
      "\n",
      "    accuracy                         0.7831      2245\n",
      "   macro avg     0.7529    0.8154    0.7599      2245\n",
      "weighted avg     0.8433    0.7831    0.7947      2245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9335    0.7392    0.8250      1614\n",
      "          ES     0.5646    0.8653    0.6834       631\n",
      "\n",
      "    accuracy                         0.7746      2245\n",
      "   macro avg     0.7491    0.8022    0.7542      2245\n",
      "weighted avg     0.8298    0.7746    0.7852      2245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9425    0.7407    0.8295      1639\n",
      "          ES     0.5559    0.8779    0.6807       606\n",
      "\n",
      "    accuracy                         0.7777      2245\n",
      "   macro avg     0.7492    0.8093    0.7551      2245\n",
      "weighted avg     0.8382    0.7777    0.7894      2245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9456    0.7253    0.8210      1631\n",
      "          ES     0.5493    0.8893    0.6791       614\n",
      "\n",
      "    accuracy                         0.7702      2245\n",
      "   macro avg     0.7475    0.8073    0.7500      2245\n",
      "weighted avg     0.8372    0.7702    0.7822      2245\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IS     0.9367    0.7214    0.8151      1601\n",
      "          ES     0.5589    0.8787    0.6832       643\n",
      "\n",
      "    accuracy                         0.7665      2244\n",
      "   macro avg     0.7478    0.8001    0.7491      2244\n",
      "weighted avg     0.8285    0.7665    0.7773      2244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X=np.array(df)\n",
    "true_labels_all = []\n",
    "predicted_labels_all = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    train_data,test_data=X[train_index],X[test_index]\n",
    "    \n",
    "    bert = build_transformer_model(\n",
    "        config_path=config_path,\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        return_keras_model=False,\n",
    "    )\n",
    "    output1 = Lambda(lambda x: x[:, 0])(bert.model.output)\n",
    "    # tmp=bert.model.output\n",
    "    \n",
    "    output = Dense(\n",
    "        units=len(labels),\n",
    "        activation='softmax',\n",
    "        kernel_initializer=bert.initializer\n",
    "    )(output1)\n",
    "    \n",
    "    model = keras.models.Model(bert.model.input, output)\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "        optimizer=Adam(2e-5),\n",
    "        metrics=['sparse_categorical_accuracy']\n",
    "    )\n",
    "    \n",
    "    train_generator = data_generator(train_data, 24)\n",
    "    test_generator = data_generator(test_data, 24)\n",
    "\n",
    "    evaluator = Evaluator()\n",
    "    history=model.fit(\n",
    "        train_generator.forfit(),\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=5, callbacks=[evaluator]\n",
    "    )\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    preall=[]\n",
    "    trueall=[]\n",
    "    for x_true, y_true in tqdm(test_generator):\n",
    "            y_pred = model.predict(x_true).argmax(axis=1)\n",
    "            preall.append(y_pred)\n",
    "            trueall.append(np.squeeze(y_true,axis=1))\n",
    "    preall=np.concatenate(preall,axis=0)\n",
    "    trueall=np.concatenate(trueall,axis=0)\n",
    "    print (classification_report(trueall,preall,digits=4,target_names=[\"IS\",\"ES\"]))\n",
    "    true_labels_all.extend(np.argmax(y_test,axis=1))\n",
    "    predicted_labels_all.extend(testpre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98644f5c-1420-4d2d-ae05-d864d65cb875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将结果转换为numpy数组\n",
    "true_labels_all = np.array(true_labels_all)\n",
    "predicted_labels_all = np.array(predicted_labels_all)\n",
    "\n",
    "# 创建一个DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'True_Label': true_labels_all,\n",
    "    'Predicted_Label': predicted_labels_all\n",
    "})\n",
    "\n",
    "# 将DataFrame保存为CSV文件\n",
    "results_df.to_csv('bert_cross_validation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
