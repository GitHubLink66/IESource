{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b825e499-ccb9-49a1-b550-ef68c48f8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df=pd.read_excel(\"Data_For Application.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834197b-ade1-4d6f-afbc-07aec84f9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from bert4keras.backend import keras, search_layer, K\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.optimizers import Adam\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from keras.layers import Lambda, Dense,Bidirectional,LSTM\n",
    "from keras.losses import kullback_leibler_divergence as kld\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807384c-e53f-4b12-8834-b9dca769315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]=df[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39271d4d-26e8-431e-8fd3-a3d3b55ccff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba_fast as jieba\n",
    "ting=[i.strip() for i in open(\"stop_words_ch-停用词表.txt\",encoding='gbk').readlines()]\n",
    "def fenci(text):\n",
    "    return [i for i in jieba.cut(str(text)) if i not in ting] \n",
    "\n",
    "df[\"text\"]=df[\"text\"].apply(lambda x:fenci(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f936a-55f3-473b-bf0e-589275105421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]=df[\"text\"].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b986d-05a5-4e10-a3e1-2abee82c0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "num_classes = 2\n",
    "maxlen = 64\n",
    "\n",
    "# BERT base\n",
    "config_path = 'chinese_roberta_www_ext/bert_config.json'\n",
    "checkpoint_path = 'chinese_roberta_www_ext/bert_model.ckpt'\n",
    "dict_path = 'chinese_roberta_www_ext/vocab.txt'\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b411a8bc-6543-4252-b787-5da43bf10de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=[\"text\"])\n",
    "df=df[\"text\"]\n",
    "# 加载数据集\n",
    "test_data=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135e68f-2e94-4132-bbcd-28028bf2a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立分词器\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
    "\n",
    "class data_generator_for_test(DataGenerator):\n",
    "    \"\"\"数据生成器\n",
    "    \"\"\"\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_segment_ids = [], []\n",
    "        for is_end, text in self.sample(random):\n",
    "#             print(text,text1,label)\n",
    "            token_ids, segment_ids = tokenizer.encode(text, maxlen=50)\n",
    "            for i in range(1):\n",
    "                batch_token_ids.append(token_ids)\n",
    "                batch_segment_ids.append(segment_ids)\n",
    "            if len(batch_token_ids) == self.batch_size  or is_end:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids,length=50)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids,length=50)\n",
    "                yield [batch_token_ids, batch_segment_ids]\n",
    "                batch_token_ids, batch_segment_ids = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0113eade-618c-4ecd-80e4-52ed760322fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    return_keras_model=False,\n",
    ")\n",
    "tmp=bert.model.output\n",
    "# tmp=bert.model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0bfd41-c465-49d8-8540-5b24cfdfbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstmout = Bidirectional(LSTM(128, return_sequences=False))(tmp)\n",
    "lstmout = Bidirectional(LSTM(128, return_sequences=False))(tmp)\n",
    "output = Dense(\n",
    "    units=2,\n",
    "    activation='softmax',\n",
    "    kernel_initializer=bert.initializer\n",
    ")(lstmout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d52a6a-7431-4a71-a7d6-818a04cc4f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Model(bert.model.input, output)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    # optimizer=Adam(1e-5),  # 用足够小的学习率\n",
    "    optimizer=Adam(2e-5),\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "def evaluate(data):\n",
    "    total, right = 0., 0.\n",
    "    for x_true, y_true in data:\n",
    "        y_pred = model.predict(x_true).argmax(axis=1)\n",
    "        y_true = y_true[:, 0]\n",
    "        total += len(y_true)\n",
    "        right += (y_true == y_pred).sum()\n",
    "    return right / total\n",
    "\n",
    "\n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    \"\"\"评估与保存\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.best_val_acc = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = evaluate(test_generator)\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            model.save_weights('bertlstm.weights'.format(1))\n",
    "        print(\n",
    "            u'val_acc: %.5f, best_val_acc: %.5f\\n' %\n",
    "            (val_acc, self.best_val_acc)\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c16690a-97c1-4741-a731-23364dda8b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "model.load_weights(\"bertlstm.weights\")\n",
    "test_generator = data_generator_for_test(test_data, 24)\n",
    "preall=[]\n",
    "for x_true in tqdm(test_generator):\n",
    "    y_pred = model.predict(x_true)\n",
    "    preall.extend(y_pred)\n",
    "\n",
    "df_result = pd.DataFrame({\"text\":df,\"pred_0\": np.array(preall)[:,0],\"pred_1\":np.array(preall)[:,1]})\n",
    "df_result.to_csv('test_result_application.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
